<a id="cloud-awareness"></a>
<h1>Cloud with Awareness</h1>
<div class="white-container">
	<div>
		<p>
			SOAJS is designed to work in a cloud environment meaning its services should be spread on different nodes, therefore we need multiple servers and this can be accomplished via virtualization. In this section we will not discuss which virtualization should be used to create the	servers, this is left up to you to pick the technology you desire, we will focus on how to install and configure SOAJS on these servers.
			<div style="width:100%; text-align:center;">
				<img ng-src="images/documentation/deployment-cloud1.png" />
			</div>
			The architecture follows the same workflow of All In One, but the difference here is that the environments are distributed on more than one machine, no more shared services or databases. Each nodes in the cloud contains a service and has a specific role to play.
		</p>
		<br/>
		<h4>Database Layer</h4>
		<p>
			As demonstrated in the above diagram, the database layer is independent from the environments. The database layer contains the replicated databases and operates with all the environments. If one environment is turned off, the database layer and other environments remain functional.
		</p>
		<br/>
		<h4>Environments</h4>

		<p>
			The architecture of the cloud is divided to Multiple Environments: <b>Dashboard</b> - <b>Production</b> - <b>CAT</b> - <b>QE</b>.<br/>
			The Dashboard environment is used to manage the content of core databases: CORE_PROVISION & CORE_SESSION.<br />
			The Dashboard also manages the users that have access to this environment ( members of the administrator group ).<br/><br />
			The other environments on the other hand are used while developing any project:
		</p>
		<ul>
			<li><b>QE</b>: This environment is used by quality engineers to test the updates and fixes that are pushed by developers after completion. Quality Engineers deploy the update on an environment that resembles the live production environment and conduct several testing approaches making sure the update works correctly in different schenarios.
			</li>
			<li><b>CAT</b>: This environment is known as staging or client approval test and is basically a replica of production. Once an update is signed off by a quality engineer, it is deployed on this environment for the client to see and approve.</li>
			<li><b>PROD</b>: This is live environment of the client. Updates that he approves from CAT are deployed on this environment and become live and available for the public.</li>
		</ul>
		<p>
			There are cases where not all environments are needed, depending on the project type and size but what is important to understand is the similarity between them. In terms of cloud architecture, they are basically the same but their usage is different; production environment has more nodes than the other three and servers more traffic and scales based on needs whereas the others are restricted between the development company and the client.<br/>
		</p>
		<p>
			Understanding the above architecture and the separation between data layer and the environments as well as the distribution of these environments and independency from one another is crucial to learning how to install SOAJS on the cloud and configure it.	Because three of these environments are similar, we will pick the Dashboard and Production environments and show how to get them up and running.
		</p>
	</div>
	<br/>
	<hr/>

	<h2>Installation</h2>
	<p>
		Three steps are needed to install SOAJS on a cloud, and in the forth step we will test them all:
	</p>
	<h3>Database Layer</h3>
	<div>
		<p>
			We begin first by installing the databases and configuring them to work as replica sets. We will require two sets of databases each replicated over 3 servers:
		</p>
		<ol>
			<li><b>CORE</b>: manages provisioned information of tenants, products, environments, dashboard members and their sessions.</li>
			<li><b>PROD</b>: contains tenant specific information as well as any other additional custom services databases information.</li>
		</ol>
			<img ng-src="images/documentation/core-db-replica.png"/><br/>
		<p>
			You can always add additional servers to distribute the load and expand. Your custom services databases do not need to be in the same set with the tenants databases, you can split those as well. Expand your database based on your need. For this tutorial we chose to group CORE databases in one group and the other databases in another group resulting in two sets.
		</p>
		<hr/>
		<p>
			Start by creating 2 Virtual Machines (VMs) and install mongodb on each of them. Give your Virtual Machines fixed IP addresses, we will connect to these two VMs later on, for this tutorial we will use two local IP address: 192.168.0.101 - 192.168.0.102 and we will refer to them as mongo-core and mongo-prod.
			<pre><code class="bash">#install MongoDB latest stable version on mongo-core VM
$ apt-get install mongodb

# edit /etc/hosts of mongo-core VM
127.0.0.1 mongo-core

#install MongoDB latest stable version on mongo-prod VM
$ apt-get install mongodb

# edit /etc/hosts of mongo-prod VM
127.0.0.1 mongo-prod</code>
			</pre>
			Once mongo is installed, create a replica set of 3 databases on each of these machines. If you are not familiar with Replica Sets, visit the official <a href="http://docs.mongodb.org/manual/tutorial/deploy-replica-set/" target="_blank">mongodb replica set documentation</a>. Our first replica set will run on the first VM and will contain the CORE databases, the second replica set will run on the second VM and will contain the production database. Complete the steps below on each of the VMs, to get both replica set up and running:
			<tabset>
				<tab heading="Core Replica Set Instructions">
					<div ng-init="loadCode(path + 'deployment/cloud-awareness/coreReplSet.txt', 'coreReplSet');"></div>
					<div id="coreReplSet"></div>
				</tab>
				<tab heading="Prod Replica Set Instructions">
					<div ng-init="loadCode(path + 'deployment/cloud-awareness/prodReplSet.txt', 'prodReplSet');"></div>
					<div id="prodReplSet"></div>
				</tab>
			</tabset>
		</p>
		<p>
			By now both VMs have mongo installed and running as replica set, navigate to mongo-core VM, install soajs.mongodb.data and import the core sample data to the database.
			<pre><code class="bash"># install soajs.mongodb.data
$ npm install soajs.mongodb.data

# import the core sample data
$ cd soajs.mongodb.data/modules/dashboard-ui/
$ chmod +x import.sh
$ ./import.sh</code>
			</pre>
			The shell script will create 1 tenant, 1 product, 1 user and 1 group in our core database and will replicate the information on all members of the replica set we created. We will use this sample data later on when everything is running. After executing the script connect to mongo and
		list the databases to verify the last step.
			<pre><code class="bash"># connect to mongo on mongo-core VM
$ mongo

# show the databases
mongo > show dbs
core_provision 0.078GB
local 0.078GB
dashboard_urac 0.078GB
admin (empty)

# switch to core_provision db
mongo > use core_provision

# list collections in the db
mongo > show collections
environment
oauth_token
oauth_urac
products
system.indexes
tenants</code></pre>
			The above command will list the databases and the collections of core_provision inside the mongo-core VM. This database information is used by SOAJS services and is considered as the core data.
		</p>
	</div>
	<br/>
	<hr/>
	<h3>Dashboard Environment</h3>
	<div>
		<p>
			<img ng-src="images/documentation/deployment-cloud-dashboard.png" class="image-right" />
			The Dashboard environment consists of a set of servers that communicate with one another to provide access to the mongo-core VM which contains the core database. The set of servers is replicated for load balancing and traffic distribution.<br />
			Several Layers are introduced to handle requests arriving to this environment:<br />
		</p>
		<ol>
			<li><b>Nginx</b>: points out the location of SOAJS controllers.</li>
			<li><b>HAProxy</b>: handles traffic distribution and load balancing.</li>
			<li><b>Controllers</b>: forwards request to designated service.</li>
			<li><b>HAproxy</b>: contains list of servers where services reside.</li>
			<li><b>Services</b>: Handle the request forwarded by the controller.</li>
		</ol>
		<br/>
		<p>
			We need 2 Servers where Nginx is installed on the first, HAproxy and the controller on the second. We also need to instruct Nginx to upstream the server that contain the controller of SOAJS which is the main gateway to SOAJS services.<br />
			You can add as many nodes as you want, for both Nginx and controller based on the traffic you have but you also need to update the configuration of Nginx and point all the IP address of these nodes.<br /><br />
			We need a 3rd Server and containing urac, dashboard and HAproxy on it. These are the SOAJS services that will access the <b>CORE</b> database in the Data layer and allow you to manage the provisioned information. <br/>
			You can add additional nodes here as well, but make sure you add their IP address in HAproxy so that the controller forwards to all of them. HAproxy is used for awarness among the servers and contains the IP addresses of the servers.
		</p>
		<br />
		<h4>Servers Setup</h4>
		<p>
			Now that we defined the layers we need and what should be installed on them, let's go ahead and create these servers. Start by creating a VM and install Nginx on it, then use the configuration located in soajs.utilities/deployment/cloud/dashboard/ to tell Nginx how many controllers we will have and where they are. For this demo, we will use the following list of IP addresses:
		</p>
		<ul>
			<li>mongo-core: 192.168.0.101</li>
			<li>Nginx: 192.168.0.50</li>
			<li>Controller 1: 192.168.0.51</li>
			<li>Controller 2: 192.168.0.52</li>
			<li>Controller 3: 192.168.0.53</li>
			<li>Services Server 1: 192.168.0.61</li>
			<li>Services Server 2: 192.168.0.62</li>
			<li>Services Server 3: 192.168.0.63</li>
		</ul>
		<br/>
		<h4>Nginx Setup</h4>
		<p>
			Once you have created all 7 VMs, install Nginx using the below command on the Nginx VM 192.168.0.50:
		</p>
		<pre><code class="bash"># install Nginx latest stable version
$ apt-get install nginx</code></pre>
		<p>
			When Nginx is installed, locate its configuration file; On Ubuntu the configuration file is located in /etc/nginx/nginx.conf. Open that file in edit mode, scroll to the bottom and instruct nginx to also look at the soajs.utilities/deployment/cloud/dashboard/nginx/conf/ folder and load all the configuration files in it, add the line before the closing bracelet of http inside the nginx.conf.
		</p>
		<pre><code class="javascript">http {
	# default nginx configuration goes here
	include /opt/soajs/soajs.utilities/deployment/cloud/dashboard/nginx/conf/*.conf;
}</code></pre>
		<p>
			This line will now load the Nginx configuration that SOAJS needs when Nginx starts. Inside the conf folder, you will find a file named upstream.conf. If you have chosen different IP addresses for your controllers, make sure you updated the entries in that file.<br/>
			Edit your hosts file and add 2 entries to point out that these domains are on your local machine.
		</p>
		<pre><code class="bash"># edit /etc/hosts
$ sudo gedit /etc/hosts

# add these lines in /etc/hosts
127.0.0.1 api.soajs.org
127.0.0.1 dashboard.soajs.org

# start Nginx
$ sudo nginx</code></pre>
		<p>
			<em>You can also copy these entries from soajs.utilities/deployment/cloud/dashboard/hosts to your /etc/hosts file.</em><br/>
			When Nginx starts, test the configuration you just created by opening your browser and invoking 2 domains: <b>api.soajs.org</b> and <b>dashboard.soajs.org</b>. Nginx will reply with a <b>502 Bad Gateway</b> Error instead of Server not Found. Till this point, this is normal because we
			haven't started any service yet, but the important thing is that Nginx is now redirecting the requests to a local SOAJS server assuming that the later is up and running.
		</p>
		<br/>
		<h4>Services Setup</h4>
		<p>
			Now let's install the services on the other VMs:
		</p>
		<ul>
			<li>3 VM will contain the controllers and HAproxy</li>
			<li>3 VM will contain Urac, Dashboard services and HAproxy</li>
		</ul>
		<p>
			<em><u>Note:</u> you can always create 2 VMs, install the services on them, then clone those VMs and change their IP addresses.</em><br/><br/>
			On each controller VM, install nodejs and HAproxy, then install the controller and the utilities of SOAJS.<br/>
			Execute the below commands in your terminal:
		</p>
		<pre><code class="bash"># install haproxy
$ apt-get install haproxy

# install nodejs
$ apt-get install nodejs

# create folder path to put all soajs components in it
$ mkdir -p /opt/soajs/node_modules/

# install SOAJS controller and utilities
$ npm install soajs.controller
$ cd soajs.controller

$ npm install soajs.utilities</code></pre>
		<p>
			Configure HAproxy to tell the controllers what are the IP address of the services VMs.<br />
			First create a backup of the default HAproxy file in /etc/haproxy/haproxy.cf.<br />
			Copy the file soajs.utilities/deployment/cloud/dashboard/ to /etc/haproxy/ and rename it to haproxy.cfg.<br />
			<em>Keep in mind that if you have chosen a different IP set for the services, you need to edit this file and change the IP address in it to meet your configuration.</em>
		</p>
		<br/>
		<p>
			Controller is done, proceed to the services VMs.<br />
			In the diagram above we have 3 servers for SOAJS services whose IP addresses 192.168.0.61/62/63.<br />
			On each service VM, install nodejs and HAproxy then install the utilities, urac and dashboard services.<br />
		</p>
		<pre><code class="bash"># install haproxy
$ apt-get install haproxy

# install nodejs
$ apt-get install nodejs

# create folder path to put all soajs components in it
$ mkdir -p /opt/soajs/node_modules/

# install soajs.utilities
$ npm install soajs.utilities

# install soajs.urac
$ npm install soajs.urac

# install soajs.dashboard
$ npm install soajs.dashboard</code>
		</pre>
		<p>
			You also need to configure HAproxy on these 3 VMs to point to the controller VMs. Again locate HAproxy configuration file, create a backup copy of /etc/haproxy/haproxy.cfg, and copy soajs.utilities/deployment/cloud/dashboard/dashboard-services-haproxy.cfg to /etc/haproxy/ and rename it to haproxy.cfg.<br />
			<em>If you chose to use different IP addresses than the ones in this tutorial, keep in mind you need to update this configuration file as well and set the correct IP addresses values.</em>
		</p>
		<p>
			Now point out the database server address on the services VM so that these services can connect to mongo-core, edit the /etc/hosts file on each service VM and add the following entry:
		</p>
		<pre><code class="bash"># edit /etc/hosts
192.168.0.101 mongo-core</code></pre>
		<br/>
		<h4>Point out the Registry Profile</h4>
		<p>
			The final step to complete this environment setup is to use the correct SOAJS environment project. As mentioned in the <a href="#/documentation/core/registry">Registry</a>, SOAJS supports multiple projects, and in this case we need to use the dashboard project that contains the environment variables that we need for this cloud using the above IP addresses from the tutorial. The dashboard project is located in soajs.utilities/deployment/cloud/dashboard/profiles/dashboard.<br />
			In all 6 VMS where we installed soajs.utilities, create 3 environment variables and give them the following values:
		</p>
		<pre><code class="bash"># set the environment name to dashboard
$ export SOAJS_ENV=dashboard

# set the project name to dashboard
$ export SOAJS_PRJ=dashboard

# point out the location of the project
$ export SOAJS_REGDIR=/opt/soajs/node_modules/soajs.utilities/deployment/cloud/dashboard/</code></pre>
		<br/>
		<h4>Start the Services</h4>
		<p>
			Once you completed all above steps, start all the services in all 6 VMs and the Dashboard Environment will run.
		</p>
		<pre><code class="bash"># repeat the below command for all controllers
$ cd /opt/soajs/node_modules/soajs.controller
$ node .

# repeat the below command for all urac
$ cd /opt/soajs/node_modules/soajs.urac
$ node .

# repeat the below command for all dashboard
$ cd /opt/soajs/node_modules/soajs.dashboard
$ node .

# repeat the below command on all servers containing HAproxy
$ service haproxy start</code></pre>
	</div>
	<br/>
	<hr/>
	<h3>Production Environment</h3>
	<!--<accordion-group heading="Step 3: Production Environment">
		<p>
			The Production environment consists of a set of servers that communicate with one another to provide access to the mongo-prod VM which contains the data databases that are used by tenant services and your custom made services. The set of servers is also replicated for load balancing and traffic distribution. The setup is close to the above dashboard environment with one difference, we don't need the dashboard service here.<br />
			We will create a VM and install Nginx on it. We will instruct Nginx to upstream 3 servers that contain the controller of SOAJS which is the main gateway so that all requests arriving to the services get handled by all 3 servers.<br />
			The Environment will contain an additional server that runs the urac, oAuth and your custom services. The urac service in this case is tenant driven this means that every tenant you create will have its own database, its own users and groups therefore, in this tutorial we will refer to it as tenant_urac when it comes to this environment.<br />
			The image below demonstrate what the Production Environment will look like when we complete this step.<br />
			<img ng-src="images/documentation/cloud-dashboard-prod.png" /><br />
			As you can see, the setup is quite close to what we did in the dashboard environment. We made one difference here, we chose to use 9 servers: 3 for controllers, 3 for soajs services and 3 for your custom services. You can merge the servers that contains soajs services with your custom services if you want to reduce the numbers of servers from 9 to 6.<br /><br />
			Notice that here as well, the servers are replicated and that HAproxy is present and used to tell point out the servers IP addresses for the controllers and our services as demonstrated by the <span style="color:blue;">blue</span> and <span style="color:red;">red</span> arrows. Here is the list of IP addresses we will use for this environment:
		</p>
		<ul>
			<li>mongo-prod: 192.168.0.102</li>
			<li>Nginx: 192.168.0.70</li>
			<li>Controller 1: 192.168.0.71</li>
			<li>Controller 2: 192.168.0.72</li>
			<li>Controller 3: 192.168.0.73</li>
			<li>SOAJS Services Server 1: 192.168.0.81</li>
			<li>SOAJS Services Server 2: 192.168.0.82</li>
			<li>SOAJS Services Server 3: 192.168.0.83</li>
			<li>Custom Service Server 1: 192.168.0.91</li>
			<li>Custom Service Server 2: 192.168.0.92</li>
			<li>Custom Service Server 3: 192.168.0.93</li>
		</ul>
		<p>
			Go ahead and create all these VMs with the exception of the mongo-prod, we already did that. Install Nginx on the first VM and for the remaining 9 VMS install haproxy and nodejs on all of them. You will also need to create the soajs directory and install soajs.utilities on them all.
		</p>
		<b><u>Nginx Setup:</u></b>
		<p>
			Once you have created all 10 VMs, install Nginx using below the command on the Nginx VM 192.168.0.70:
			<pre><code class="bash"># install Nginx latest stable version
$ apt-get install nginx</code></pre>
			When Nginx is installed, locate its configuration file; On Ubuntu the configuration file is located in /etc/nginx/nginx.conf. Open that file in edit mode, scroll to the bottom and instruct nginx to also look at the soajs.utilities/deployment/cloud/prod/nginx/conf/ folder and load all the configuration files in it, add the line before the closing bracelet of http inside the nginx.conf.
			<pre><code class="javascript">http {
# default nginx configuration goes here
include /opt/soajs/soajs.utilities/deployment/cloud/prod/nginx/conf/*.conf;
}</code></pre>
			This line will now load the Nginx configuration that SOAJS needs when Nginx starts. Inside the conf folder, you will find a file named upstream.conf. If you have chosen different IP addresses for your controllers, make sure you updated the entries in that file.<br/>
			Edit your hosts file and add the following entry to point out the domain of the the controller.
			<pre><code class="bash">$ sudo gedit /etc/hosts
127.0.0.1 api.soajs.org</code></pre>
			<em>You can also copy these entries from soajs.utilities/deployment/cloud/prod/hosts to your /etc/hosts file.</em><br/>
		Go ahead and Start Nginx Now:
		<pre><code class="bash">$ sudo Nginx</code></pre>
		When Nginx starts, test the configuration you just created by opening your browser and invoking the domain: <b>api.soajs.org</b>. Nginx will reply with a <b>502 Bad Gateway</b> Error instead of Server not Found. Till this point, this is normal because we haven't started any service yet, but the important thing is that Nginx is now redirecting the requests to a local SOAJS server assuming that the later is up and running.
		</p>
		<br/>
		<b><u>Services Setup:</u></b>
		<p>
			Now let's install the services on the remaining 9 VMs; 3 of them will contain controllers and 3 will contain oAuth and Urac and 3 will contain your services.<br/>
			On each controller VM, install nodejs and HAproxy, then install the controller and the utilities of SOAJS.<br/>
			Execute the below commands in your terminal:
			<pre><code class="bash"># install haproxy
$ apt-get install haproxy

# install nodejs
$ apt-get install nodejs

# create folder path to put all soajs components in it
$ mkdir -p /opt/soajs/node_modules/

# install SOAJS controller and utilities
$ npm install soajs.controller
$ cd soajs.controller

$ npm install soajs.utilities</code>
			</pre>
		The next step requires to configure HAproxy to tell the controllers what are the IP address of the services that we have in the cloud.<br />
		First create a backup of the default HAproxy file in /etc/haproxy/haproxy.cfg, then Navigate to soajs.utilities/deployment/cloud/prod/ and copy the file prod-controller-haproxy.cfg to /etc/haproxy/ and rename it to haproxy.cfg.<br />
		Keep in mind that if you have chosen a different IP set for the services, you need to edit this file and change the IP address in it to meet your configuration.
		</p>
		<p>
			Once the controller VMs are completed, we need to set up the remaining services. In the diagram above we have 6 servers and we gave them IP addresses 192.168.0.81/82/83/91/92/93. On each service VM, install nodejs and HAproxy then install the utilities, urac, oauth and your service.<br />
		</p>
		<pre><code class="bash"># install haproxy
$ apt-get install haproxy

# install nodejs
$ apt-get install nodejs

# create folder path to put all soajs components in it
$ mkdir -p /opt/soajs/node_modules/

# install soajs.utilities
$ npm install soajs.utilities

# install soajs.urac
$ npm install soajs.urac

# install soajs.oauth
$ npm install soajs.oauth

# install your_service
$ npm install your_service</code>
		</pre>
		<p>
			You also need to configure HAproxy on these 6 VMs to point to the controller VMs. Again locate HAproxy configuration file and create a backup copy of /etc/haproxy/haproxy.cfg, then Navigate to soajs.utilities/deployment/cloud/prod/ and copy the file prod-services-haproxy.cfg to /etc/haproxy/ and rename it to haproxy.cfg.<br /> If you chose to use different IP addresses than the ones in this tutorial, keep in mind you need to update this configuration file as well and set the correct IP addresses values.
		</p>
		<p>
			Now point out the database servers so that both the controllers and the services can connect to mongo-core and to mongo-prod. In this environment, the services need to read from core and from the prod databases. In the dashboard environment we only needed to connect to core. The logic behind this strategy is that when a request is made and a tenant key is provided for example, the tenant records are located in core and to cross reference the key value, data from core need to be accessible.<br />
			So in all 9 VMs we created last, edit the /etc/hosts file and add the following entry:
			<pre><code class="bash"># edit /etc/hosts
192.168.0.101 mongo-core
192.168.0.102 mongo-prod</code>
			</pre>
		<img ng-src="images/documentation/cloud-prod-env-full.png" /><br />
		<br />By now you have completed 2/3rd of setting up this environment and you should have something that resembles the above diagram.<br /><br />
		Notice the <span style="color:purple;">purple</span> arrows as they point out that all our servers in the production environment connect to the production database server and the <span style="color:green;">green</span> arrows point out the connection to the core database server.<br />
		Here is a summary of list of VMs we used for this environment and their IP addresses:
		</p>
		<p>
			The final step to complete this environment setup is to use the correct SOAJS environment project. As mentioned in the <a href="#/documentation/core/registry">Registry</a>, SOAJS supports multiple projects, and in this case we need to use the prod project that contains the environment variables that we need for this cloud using the above IP addresses from the tutorial. The prod project is located in soajs.utilities/deployment/cloud/prod/profiles/prod.<br />
			In all 9 VMS where we installed soajs.utilities, create 3 environment variables and give them the following values:
		</p>
		<pre><code class="bash"># set the environment name to prod
$ export SOAJS_ENV=prod

# set the project name to prod
$ export SOAJS_PRJ=prod

# point out the location of the project
$ export SOAJS_REGDIR=/opt/soajs/node_modules/soajs.utilities/deployment/cloud/prod/</code></pre>
		<p>
			Edit the file /opt/soajs/node_modules/soajs.utilities/deployment/cloud/prod/environment/prod.js, at the bottom you will see a registry entry for your service, make sure you set the correct values before you start the services.
			<pre><code class="javascript">
"your_service": {
"extKeyRequired": true,
"port": 4003,
"host": "127.0.0.1",
"url": "http://127.0.0.1:4000/your_service"
}</code>
			</pre>
			<u>Note:</u> the varialbe <b>your_service</b> is also present at /opt/soajs/node_modules/soajs.utilities/deployment/cloud/prod/prod-controller-haproxy.cfg, make sure you update the value as well.<br />
			Once you completed all above steps, start all the services in all 9 VMs and the Production Environment will run.
		</p>
		</accordion-group>-->
	<br/>
	<hr/>
	<h3>Testing the service:</h3>
	<!--<accordion-group heading="Step 4: Testing it All">
		<p>
			We mentioned in the <a href="#/documentation/services/controller">Controller</a> section that you can run a maintenance check on any service built with SOAJS. When a service starts, it will listen to two ports: the default port and the maintenance port.<br />
			Let's run some maintenance heartbeat requests to see the status of our services.<br />
			Navigate to the Dashboard Nginx VM, then execute the following commands:
		</p>
		<pre><code class="bash"># in a new terminal
$ curl -X GET "http://192.168.0.51:5000/heartbeat"
{"result":true,"ts":1427373613796,"service":{"service":"CONTROLLER","type":"rest","route":"/heartbeat"}}

$ curl -X GET "http://192.168.0.52:5000/heartbeat"
{"result":true,"ts":1427373613796,"service":{"service":"CONTROLLER","type":"rest","route":"/heartbeat"}}

$ curl -X GET "http://192.168.0.53:5000/heartbeat"
{"result":true,"ts":1427373613796,"service":{"service":"CONTROLLER","type":"rest","route":"/heartbeat"}}
		</code></pre>
		<p>
			We just ran a heartbeat check on the controller. The controller runs on port 4000 making his maintenance port 4000 + 1000 = 5000. Make a request to port 5000 followed by /hearbeat as a path parameter. You can perform the same operation for any other service. In the registry of SOAJS under dev environment, the services are configured to run on specific port numbers. The controller uses 4000, Urac 4001, oAuth 4002 and Dashboard 4003. This means their maintenance ports are equal to 5000, 5001, 5002, 5003. Let's run the heartbeat on every service other than the controller:
		</p>
		<pre><code class="bash"># in the same terminal
$ curl -X GET "http://192.168.0.51:5001/heartbeat"
{"result":true,"ts":1427373613796,"service":{"service":"URAC","type":"rest","route":"/heartbeat"}}

$ curl -X GET "http://192.168.0.51:5002/heartbeat"
{"result":true,"ts":1427373613796,"service":{"service":"OAUTH","type":"rest","route":"/heartbeat"}}

$ curl -X GET "http://192.168.0.51:5003/heartbeat"
{"result":true,"ts":1427373613796,"service":{"service":"DASHBOARD","type":"rest","route":"/heartbeat"}}
		</code></pre>
		<u>Note:</u> The above command sent requests to 192.168.0.51, you can also run this command for 192.168.0.52 and 192.168.0.53.
		<p>
			The dashboard services are running as expected, let's test the production environment.<br /><br /><br />
			Navigate to the Production Nginx VM, then execute the following commands:
		</p>
		<pre><code class="bash"># in a new terminal
$ curl -X GET "http://192.168.0.71:5000/heartbeat"
{"result":true,"ts":1427373613796,"service":{"service":"CONTROLLER","type":"rest","route":"/heartbeat"}}

$ curl -X GET "http://192.168.0.72:5000/heartbeat"
{"result":true,"ts":1427373613796,"service":{"service":"CONTROLLER","type":"rest","route":"/heartbeat"}}

$ curl -X GET "http://192.168.0.73:5000/heartbeat"
{"result":true,"ts":1427373613796,"service":{"service":"CONTROLLER","type":"rest","route":"/heartbeat"}}
		</code></pre>
		<p>
			Then using the same approach as above, test the remaining services.
		</p>
		<pre><code class="bash"># in a new terminal
$ curl -X GET "http://192.168.0.71:5001/heartbeat"
{"result":true,"ts":1427373613796,"service":{"service":"URAC","type":"rest","route":"/heartbeat"}}

$ curl -X GET "http://192.168.0.71:5002/heartbeat"
{"result":true,"ts":1427373613796,"service":{"service":"OAUTH","type":"rest","route":"/heartbeat"}}

$ curl -X GET "http://192.168.0.71:5004/heartbeat"
{"result":true,"ts":1427373613796,"service":{"service":"your_service","type":"rest","route":"/heartbeat"}}
		</code></pre>
		</accordion-group>
	</accordion>-->
	<br/>
	<hr/>
	<p>
		When the above steps are completed successfully, the cloud will be up and running, all services working and you can now login and use the interface. In your browser, open <a href="http://dashboard.soajs.org" target="_blank">http://dashboard.soajs.org</a>, login with username: <b>admin</b> and password: <b>password</b>. Once inside, change these credentials in Edit Profile section, you can also navigate through the sections of the dashboard to manage tenants, products and other information as explained in <a href="#/documentation/services/dashboard-service">Dashboard Services</a> and <a href="#/documentation/ui/dashboard-setup">Dashboard UI</a>.
	</p>
	<div class="redFlag">zid how to create your service hone w farje bi diagram wein betkoun nezle</div>
</div>